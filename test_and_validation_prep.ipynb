{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e481cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unify_data as dp # my file for dealing with temporal data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pykalman import KalmanFilter\n",
    "import librosa as lb # dealing with audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3b92cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# support fucntions\n",
    "def one_d_kalman_filter(df):\n",
    "    \"\"\"basic 1d kalman filterfunction based on the function provided by the professor (sigh)\"\"\"\n",
    "    for i,column in enumerate(df.columns):\n",
    "        print(f\"{i} column out of {len(df.columns)}\")\n",
    "        if not is_numeric_dtype(df[column]):\n",
    "            continue\n",
    "        else:\n",
    "            kf =  KalmanFilter(transition_matrices=[[1]], observation_matrices=[[1]]) #transition and observation matrices for computations\n",
    "            masked_values = np.ma.masked_invalid(df[column].values.astype(np.float32))\n",
    "\n",
    "            kf_params = kf.em(masked_values,n_iter=3) #optimizes Q and R (the noise estimates) and so on of the kalman filter to improve outlier detection and imputation\n",
    "            imputed_data, covariances = kf_params.smooth(masked_values) #applies the filter\n",
    "            df[column] = imputed_data\n",
    "    return df\n",
    "\n",
    "def multivariate_kalman_filter(df):\n",
    "    \"\"\"updates function from professor to multivariate kalman filter\"\"\"\n",
    "    columns_to_impute = [column for column in df.columns if  is_numeric_dtype(df[column])]\n",
    "    kf =KalmanFilter(\n",
    "        transition_matrices = np.eye(len(columns_to_impute)), #initialize transition matrix to just next state\n",
    "        observation_matrices = np.eye(len(columns_to_impute)), #initialize observation matrix to just next state\n",
    "        transition_covariance = np.eye(len(columns_to_impute))*0.5, #initialize Q to moderate uncertainty about transition model\n",
    "        observation_covariance = np.eye(len(columns_to_impute)) *0.5)#initialize R to moderate uncertainty about measurements \n",
    "    \n",
    "    masked_df = np.ma.masked_invalid(df[columns_to_impute].values.astype(np.float32))\n",
    "    kf_params = kf.em(masked_df,n_iter=3) #optimizes Q and R (the noise estimates) and so on of the kalman filter to improve outlier detection and imputation\n",
    "    imputed_data, covariances = kf_params.smooth(masked_df) #applies the filter\n",
    "    print(\"imputation of multivariate done\")\n",
    "    for i, column in enumerate(columns_to_impute):\n",
    "        df[column] = imputed_data[:,i]\n",
    "    return df\n",
    "\n",
    "def mixed_kalman_filter(df):\n",
    "    \"\"\"function that applies multivariate approach for highly correlated features and univariate for others\"\"\"\n",
    "    print(\"now correlated\")\n",
    "    correlated_columns =df[[\"Latitude (°)\",\"Longitude (°)\",\"Height (m)\"]]\n",
    "    correlated_df = multivariate_kalman_filter(correlated_df)\n",
    "    print(\"now uncorrelated\")\n",
    "    uncorrelated_columns = df.drop(df[correlated_columns])\n",
    "    uncorrelated_df = one_d_kalman_filter(uncorrelated_columns)\n",
    "    df_concat = pd.concat([correlated_df, uncorrelated_df], axis=1)\n",
    "    return df_concat\n",
    "\n",
    "def audio_to_csv(audio_file, fft_ws, w_ss, file_output):\n",
    "    \"\"\"\n",
    "    Transforms audio data into frequency and amplitude via FastFurrier Transform\n",
    "\n",
    "    Parameters:\n",
    "\n",
    "    - fft_ws: fast furrier transform window size;\n",
    "        higer => better freq resolution but worse time resolution\n",
    "    - w_ss: window step size\n",
    "        higher => better resolution but more overlap\n",
    "    \"\"\"\n",
    "    # extract audio array and sampling rate \n",
    "    y, sr = lb.load(audio_file, sr=None)\n",
    "\n",
    "    # create short time furier transform; freq as rows and time-frames as columns \n",
    "    # entries containeding amplituede and phase as complex numbers\n",
    "    mat = lb.stft(y, n_fft=fft_ws, hop_length=w_ss)\n",
    "    \n",
    "    # get magnitude  and frequencies \n",
    "    magnitude = np.abs(mat) \n",
    "    freq = lb.fft_frequencies(sr=sr, n_fft=fft_ws) # map indices in fft matrix to real values \n",
    "\n",
    "    # extract maximum freq from matrix \n",
    "    dfreq_idx =  np.argmax(magnitude, axis=0)\n",
    "    dfreq = freq[dfreq_idx]\n",
    "\n",
    "    d_magnitudes =[]\n",
    "    for i in range(magnitude.shape[1]):\n",
    "        highest = dfreq_idx[i]\n",
    "        d_magnitudes.append(magnitude[highest,i]) #collects the amplitudes per time\n",
    "\n",
    "    # create time \n",
    "    time = lb.frames_to_time(np.arange(magnitude.shape[1]),sr=sr,hop_length=w_ss)\n",
    "\n",
    "    # convert to df and save \n",
    "    pd.DataFrame({\"Common time (s)\":time,\"amplitude\":d_magnitudes,\"frequency\":dfreq}).to_csv(f\"{file_output}.csv\")\n",
    "    print(\"Audio file saved!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf103adc",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a4d8d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio file saved!\n"
     ]
    }
   ],
   "source": [
    "# transfrom audio to csv file \n",
    "audio_to_csv(\"test_audio.wav\",1024, 512, \"test_data\\\\audio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d6978e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# information required for generating data set\n",
    "path = \"test_data\"\n",
    "activs = [\"study\", \"socializing\", \"walk\", \"stairs\", \"phone\", \"walking\", \"rest\"] # activiy sequence \n",
    "rtimes= []\n",
    "\n",
    "## generate tet data set ##\n",
    "test_data = dp.get_dataset(path, activs, rtimes, \"Activity\", impute=True, custom_impute=multivariate_kalman_filter)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d253a433",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f922e89d",
   "metadata": {},
   "source": [
    "#### Add survey data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75685d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_survey = pd.read_csv(\"testdata_sresp.csv\")\n",
    "\n",
    " # add relative time experiment \n",
    "test_survey[\"Linear time\"] = None\n",
    "start_time = None\n",
    "\n",
    "for idx, time_val in enumerate(test_survey.iloc[:, 0]):\n",
    "    # extract time from timestamp and convert to min:sec,msec\n",
    "    time = time_val.split()[1][3:] + \",00\"\n",
    "    \n",
    "    # get relative time \n",
    "    if start_time is None: start_time = dp.strtime_to_sec(time)\n",
    "\n",
    "    linear_time = dp.strtime_to_sec(time) - start_time\n",
    "\n",
    "    test_survey.loc[idx, \"Linear time\"] = linear_time\n",
    "\n",
    "test_survey.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ba1566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add labels from survey data\n",
    "ctime = test_survey[\"Linear time\"]\n",
    "\n",
    "# loop over each variable to add labels \n",
    "for col in test_survey.columns[1:-1]:\n",
    "    dp.add_labels(test_data, test_survey[col], ctime, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08946d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv(\"test_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc5fb2d",
   "metadata": {},
   "source": [
    "### Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e815178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfrom audio to csv file \n",
    "audio_to_csv(\"val_audio.wav\",1024, 512, \"val_data\\\\audio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3effab27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# information required for generating data set\n",
    "path = \"val_data\"\n",
    "activs = [\"study\", \"socializing\", \"walk\", \"stairs\", \"phone\", \"walking\", \"rest\"] # activiy sequence \n",
    "rtimes= []\n",
    "\n",
    "## generate tet data set ##\n",
    "val_data = dp.get_dataset(path, activs, rtimes, \"Activity\", impute=True, custom_impute=multivariate_kalman_filter)\n",
    "val_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dd6a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4addd94",
   "metadata": {},
   "source": [
    "#### Add survey values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c539753",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_survey = pd.read_csv(\"testdata_sresp.csv\")\n",
    "\n",
    " # add relative time experiment \n",
    "val_survey[\"Linear time\"] = None\n",
    "start_time = None\n",
    "\n",
    "for idx, time in enumerate(val_survey.iloc[:, 0]):\n",
    "    # extract time from timestamp and convert to min:sec,msec\n",
    "    time = time.split()[1][3:] + \",00\"\n",
    "    \n",
    "    # get relative time \n",
    "    if start_time is None: start_time = dp.strtime_to_sec(time)\n",
    "\n",
    "    linear_time = dp.strtime_to_sec(time) - start_time\n",
    "\n",
    "    val_survey.loc[idx, \"Linear time\"] = linear_time\n",
    "\n",
    "val_survey.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376301f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add labels from survey data\n",
    "ctime = val_survey[\"Linear time\"]\n",
    "\n",
    "# loop over each variable to add labels \n",
    "for col in test_survey.columns[1:-1]:\n",
    "    dp.add_labels(val_data, val_survey[col], ctime, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78150587",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data.to_csv(\"val_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
